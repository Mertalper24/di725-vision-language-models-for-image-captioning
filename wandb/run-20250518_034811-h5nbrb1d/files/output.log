Loading dataset...
Initializing model with QLoRA...
`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.
Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use
`config.hidden_activation` if you want to override this behaviour.
See https://github.com/huggingface/transformers/pull/29402 for more details.
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:08<00:00,  2.73s/it]
trainable params: 11,298,816 || all params: 2,934,765,296 || trainable%: 0.3850
C:\Users\Mert\AppData\Local\Programs\Python\Python39\lib\site-packages\transformers\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
Traceback (most recent call last):
  File "C:\Users\Mert\Desktop\di725-vision-language-models-for-image-captioning\train_with_wandb.py", line 161, in <module>
    main()
  File "C:\Users\Mert\Desktop\di725-vision-language-models-for-image-captioning\train_with_wandb.py", line 117, in main
    training_args = TrainingArguments(
  File "<string>", line 134, in __init__
  File "C:\Users\Mert\AppData\Local\Programs\Python\Python39\lib\site-packages\transformers\training_args.py", line 1662, in __post_init__
    raise ValueError(
ValueError: --load_best_model_at_end requires the saving steps to be a round multiple of the evaluation steps, but found 10, which is not a round multiple of 100.
Traceback (most recent call last):
  File "C:\Users\Mert\Desktop\di725-vision-language-models-for-image-captioning\train_with_wandb.py", line 161, in <module>
    main()
  File "C:\Users\Mert\Desktop\di725-vision-language-models-for-image-captioning\train_with_wandb.py", line 117, in main
    training_args = TrainingArguments(
  File "<string>", line 134, in __init__
  File "C:\Users\Mert\AppData\Local\Programs\Python\Python39\lib\site-packages\transformers\training_args.py", line 1662, in __post_init__
    raise ValueError(
ValueError: --load_best_model_at_end requires the saving steps to be a round multiple of the evaluation steps, but found 10, which is not a round multiple of 100.
